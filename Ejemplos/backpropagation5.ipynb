{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Unit:\n",
    "    def __init__(self, value, grad = None):\n",
    "        self.value = value\n",
    "        if grad == None:\n",
    "            self.grad = np.zeros(value.shape)\n",
    "        else:\n",
    "            self.grad = grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PerceptronGate:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.z = None\n",
    "    def sigmoid(x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        dotProd = self.x.value.dot(self.y.value)\n",
    "        s = PerceptronGate.sigmoid(dotProd)\n",
    "        self.z = Unit(s, 0.0)\n",
    "        return self.z\n",
    "    def backward(self):\n",
    "        s = self.z.value\n",
    "        self.x.grad += self.y.value * s * (1 - s) * self.z.grad\n",
    "        self.y.grad += self.x.value * s * (1 - s) * self.z.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LossGate:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.z = None\n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = Unit(0.5*(self.x.value-self.y.value)**2, 0.0)\n",
    "        return self.z\n",
    "    def backward(self):\n",
    "        self.x.grad += (self.x.value-self.y.value) * self.z.grad\n",
    "        self.y.grad += -1.0*(self.x.value-self.y.value) * self.z.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perceptron0_0 = PerceptronGate()\n",
    "perceptron0_1 = PerceptronGate()\n",
    "perceptron0_2 = PerceptronGate()\n",
    "perceptron1_0 = PerceptronGate()\n",
    "loss = LossGate()\n",
    "\n",
    "w0_0 = Unit(np.random.randn(10))\n",
    "w0_1 = Unit(np.random.randn(10))\n",
    "w0_2 = Unit(np.random.randn(10))\n",
    "w1_0 = Unit(np.random.randn(3))\n",
    "\n",
    "x = Unit(np.random.randn(10))\n",
    "y = Unit(np.random.randint(0,2), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# forward pass\n",
    "def forwardNetwork():\n",
    "    p0_0 = perceptron0_0.forward(w0_0,x)\n",
    "    p0_1 = perceptron0_1.forward(w0_1,x)\n",
    "    p0_2 = perceptron0_2.forward(w0_2,x)\n",
    "    p0 = Unit(np.array([p0_0.value, p0_1.value, p0_2.value]))\n",
    "    p = perceptron1_0.forward(p0, w1_0)\n",
    "    return loss.forward(p,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# backward pass\n",
    "def backwardNetwork(output):\n",
    "    output.grad = 1.0;\n",
    "    loss.backward()\n",
    "    perceptron1_0.backward()\n",
    "    perceptron0_0.z.grad = perceptron1_0.x.grad[0]\n",
    "    perceptron0_0.backward()\n",
    "    perceptron0_1.z.grad = perceptron1_0.x.grad[1]\n",
    "    perceptron0_1.backward()\n",
    "    perceptron0_2.z.grad = perceptron1_0.x.grad[2]\n",
    "    perceptron0_2.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current loss: 0.0854549517452\n",
      "current loss: 0.0849835545643\n",
      "current loss: 0.0842808061818\n",
      "current loss: 0.0833518968735\n",
      "current loss: 0.0822037010201\n",
      "current loss: 0.0808447344821\n",
      "current loss: 0.0792850975975\n",
      "current loss: 0.0775364017639\n",
      "current loss: 0.0756116775897\n",
      "current loss: 0.0735252628296\n",
      "current loss: 0.0712926687778\n",
      "current loss: 0.068930424474\n",
      "current loss: 0.0664558989614\n",
      "current loss: 0.0638871028886\n",
      "current loss: 0.0612424719116\n",
      "current loss: 0.0585406355489\n",
      "current loss: 0.0558001762888\n",
      "current loss: 0.053039384742\n",
      "current loss: 0.0502760173858\n",
      "current loss: 0.0475270638705\n",
      "current loss: 0.0448085308951\n",
      "current loss: 0.0421352492846\n",
      "current loss: 0.039520710108\n",
      "current loss: 0.0369769345212\n",
      "current loss: 0.0345143805778\n",
      "current loss: 0.0321418886218\n",
      "current loss: 0.029866665192\n",
      "current loss: 0.0276943037462\n",
      "current loss: 0.0256288390636\n",
      "current loss: 0.0236728310074\n",
      "current loss: 0.0218274724804\n",
      "current loss: 0.0200927159088\n",
      "current loss: 0.0184674124541\n",
      "current loss: 0.0169494583266\n",
      "current loss: 0.0155359430196\n",
      "current loss: 0.0142232949231\n",
      "current loss: 0.0130074205458\n",
      "current loss: 0.0118838343976\n",
      "current loss: 0.0108477774137\n",
      "current loss: 0.0098943225726\n",
      "current loss: 0.00901846705408\n",
      "current loss: 0.00821521086756\n",
      "current loss: 0.00747962235107\n",
      "current loss: 0.00680689129766\n",
      "current loss: 0.00619237071371\n",
      "current loss: 0.00563160836722\n",
      "current loss: 0.00512036935809\n",
      "current loss: 0.0046546509514\n",
      "current loss: 0.004230690876\n",
      "current loss: 0.0038449702167\n",
      "current loss: 0.00349421193146\n",
      "current loss: 0.00317537591639\n",
      "current loss: 0.00288565142655\n",
      "current loss: 0.00262244754824\n",
      "current loss: 0.00238338231045\n",
      "current loss: 0.00216627092361\n",
      "current loss: 0.00196911354398\n",
      "current loss: 0.00179008288244\n",
      "current loss: 0.00162751190739\n",
      "current loss: 0.00147988183244\n",
      "current loss: 0.0013458105302\n",
      "current loss: 0.00122404147194\n",
      "current loss: 0.00111343325982\n",
      "current loss: 0.00101294979109\n",
      "current loss: 0.000921651072389\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "step_size = 0.01;\n",
    "s = forwardNetwork()\n",
    "#print(s.value)\n",
    "while s.value > 1e-3:\n",
    "    backwardNetwork(s)\n",
    "    w0_0.value -= step_size * w0_0.grad\n",
    "    w0_1.value -= step_size * w0_1.grad\n",
    "    w0_2.value -= step_size * w0_2.grad\n",
    "    w1_0.value -= step_size * w1_0.grad\n",
    "    s = forwardNetwork()\n",
    "    print('current loss: ' + str(s.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
